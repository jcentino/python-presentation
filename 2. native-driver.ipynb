{
 "metadata": {
  "name": "",
  "signature": "sha256:bb30833ecf575c0bf8e7de999d094e25d36665cecbac4335268f5be48614daf1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Native Driver Introduction\n",
      "=============================\n",
      "\n",
      "Welcome to the Python native driver tutorial.  This tutorial will be constantly evolving as feedback is incorperated.  Pull requests are encouraged!  This is fully open source, feel free to fork and deliver it at other meetups!\n",
      "\n",
      "Check out the [documenation](http://datastax.github.io/python-driver/) and the [github repo](https://github.com/datastax/python-driver)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is necessary to get inline plots from matplotlib\n",
      "%matplotlib inline "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're going to assume a keyspace named tutorial exists\n",
      "\n",
      "In a CQL shell, we can do this:\n",
      "\n",
      "> CREATE KEYSPACE tutorial WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\n",
      "\n",
      "we'll create the rest of the tables programatically"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here we set up our database connection\n",
      "from cassandra.cluster import Cluster\n",
      "cluster = Cluster()\n",
      "\n",
      "# a session manages the connection pool for us\n",
      "session = cluster.connect(\"tutorial\")\n",
      "print \"Connected\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Table Setup\n",
      "-------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# basic table setup\n",
      "tables = [\"photo\", \"comment\"]\n",
      "\n",
      "# drop the existing ones.  can't use a placeholder for DROP TABLE so we just use python string interpolation\n",
      "for table in tables:\n",
      "    session.execute(\"DROP TABLE if exists %s\" % table)\n",
      "    \n",
      "photo = \"\"\"\n",
      "CREATE TABLE photo (\n",
      "  photo_id uuid,\n",
      "  name text,\n",
      "  PRIMARY KEY (photo_id)\n",
      ")\n",
      "\"\"\"\n",
      "\n",
      "comment = \"\"\"\n",
      "CREATE TABLE comment (\n",
      "  photo_id uuid,\n",
      "  comment_id timeuuid,\n",
      "  comment text,\n",
      "  PRIMARY KEY (photo_id, comment_id)\n",
      ") WITH CLUSTERING ORDER BY (comment_id DESC)\n",
      "\"\"\"\n",
      "\n",
      "session.execute(photo)\n",
      "session.execute(comment)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prepared Statements\n",
      "========================\n",
      "We're going to populate photos using prepared statements.\n",
      "\n",
      "Prepared statements are more secure and decrease server load."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import uuid\n",
      "insert = session.prepare(\"INSERT INTO photo (photo_id, name) VALUES (?, ?)\")\n",
      "\n",
      "for x in range(100):\n",
      "    session.execute(insert, (uuid.uuid4(), \"test %d\" % x))\n",
      "\n",
      "for photo in session.execute(\"SELECT * from photo limit 5\"):\n",
      "    print photo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lets get a nice visual of some sensor data!\n",
      "\n",
      "session.execute(\"DROP TABLE IF EXISTS sensor_data\")\n",
      "sensor_table = \"\"\"\n",
      "CREATE TABLE sensor_data (\n",
      "  sensor_id uuid,\n",
      "  created_at timeuuid,\n",
      "  reading int,\n",
      "  PRIMARY KEY (sensor_id, created_at)\n",
      ") WITH CLUSTERING ORDER BY (created_at DESC)\n",
      "\"\"\"\n",
      "\n",
      "session.execute(sensor_table)\n",
      "\n",
      "from uuid import uuid1, uuid4\n",
      "from random import randint\n",
      "\n",
      "insert = session.prepare(\"INSERT INTO sensor_data (sensor_id, created_at, reading) VALUES (?, ?, ?)\")\n",
      "\n",
      "sid = uuid4()\n",
      "for x in range(100):\n",
      "    session.execute(insert, (sid, uuid.uuid1(), randint(1, 1000)))\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualizing Data with Matplotlib\n",
      "---------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.mlab as mlab\n",
      "import matplotlib.pyplot as plt\n",
      "# plot it out\n",
      "\n",
      "tmp = session.execute(\"SELECT * from sensor_data WHERE sensor_id = %s\", [sid] )\n",
      "raw_readings = [x.reading for x in tmp]\n",
      "\n",
      "num_bins = 20\n",
      "mu = 10\n",
      "sigma = 15\n",
      "\n",
      "# the histogram of the data\n",
      "\n",
      "n, bins, patches = plt.hist(raw_readings, num_bins, normed=0, facecolor='green', alpha=0.5)\n",
      "# add a 'best fit' line\n",
      "y = mlab.normpdf(bins, mu, sigma)\n",
      "plt.plot(bins, y, 'r--')\n",
      "plt.xlabel('Reading')\n",
      "plt.ylabel('Number of readings')\n",
      "plt.title(r'Histogram of sensor data: $\\mu=100$, $\\sigma=15$')\n",
      "\n",
      "# Tweak spacing to prevent clipping of ylabel\n",
      "plt.subplots_adjust(left=0.15)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if you need cluster meta data\n",
      "sensor = cluster.metadata.keyspaces['tutorial'].tables['sensor_data']\n",
      "print \"Sensor table: \", sensor\n",
      "print \"Columns:\", sensor.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Performance\n",
      "============"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Python driver works best when taking advantage of it's asynchronous features.  \n",
      "\n",
      "First, we'll insert our sensor data.  Here's we'll use a callback to insert some data after we've created the initial sensor entry."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime\n",
      "from random import randint\n",
      "\n",
      "session.execute(\"TRUNCATE sensor_data\")\n",
      "session.execute(\"DROP TABLE IF EXISTS sensor\")\n",
      "sensor_table = \"\"\"\n",
      "CREATE TABLE sensor (\n",
      "  sensor_id uuid,\n",
      "  name text,\n",
      "  created_at timestamp,\n",
      "  PRIMARY KEY (sensor_id)\n",
      ")\n",
      "\"\"\"\n",
      "\n",
      "session.execute(sensor_table)\n",
      "\n",
      "\"\"\"\n",
      "from earlier defined table:\n",
      "\n",
      "    sensor_data:\n",
      "      sensor_id uuid,\n",
      "      created_at timeuuid,\n",
      "      reading int,\n",
      "\"\"\"\n",
      "\n",
      "insert_sensor = session.prepare(\"INSERT INTO sensor (sensor_id, name, created_at) VALUES (?, ?, ?)\")\n",
      "insert_sensor_data = session.prepare(\"INSERT INTO sensor_data (sensor_id, created_at, reading) VALUES (?, ?, ?)\")\n",
      "\n",
      "# CALLBACK: for each sensor we're going to create 100 sensor entires\n",
      "def create_sensor_entries_callback(response, sensor_id):\n",
      "    print \"CALLBACK\"\n",
      "    for x in range(10):\n",
      "        session.execute_async(insert_sensor_data, (sensor_id, uuid1(), randint(1, 1000)))\n",
      "\n",
      "futures = []\n",
      "sensor_ids = []\n",
      "\n",
      "for x in range(10):\n",
      "    sensor_id = uuid4()\n",
      "    print sensor_id\n",
      "    future = session.execute_async(insert_sensor, (sensor_id, \"sensor %d\" % x, datetime.now()))\n",
      "    future.add_callback(create_sensor_entries_callback, sensor_id)\n",
      "    futures.append(future)\n",
      "    sensor_ids.append([sensor_id]) # we'll save this for later as a list of tuples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"This is to clear the rest of the callbacks (ipython notebook issue)\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Concurrency with `cassandra.concurrent`\n",
      "------------------------------------------\n",
      "We have other options to take advantage of the built in concurrency.  Let's try selecting the last 3 readings from each sensor back out.  We can prepare a statement"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cassandra.concurrent import execute_concurrent_with_args\n",
      "\n",
      "select_statement = session.prepare(\"SELECT * FROM sensor_data WHERE sensor_id=? ORDER BY created_at DESC LIMIT 1\")\n",
      "\n",
      "result = execute_concurrent_with_args(session, select_statement, sensor_ids)\n",
      "for x in result:\n",
      "    print \"result:\", x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Understanding Performance Through Tracing\n",
      "------------------------------------------------\n",
      "The native driver exposes a convenient means of getting metrics from Cassandra's internals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cassandra.query import SimpleStatement\n",
      "statement = SimpleStatement(\"SELECT * from sensor_data WHERE sensor_id=%s LIMIT 1\")\n",
      "result = session.execute(statement, sensor_ids[0], trace=True)\n",
      "\n",
      "for event in statement.trace.events:\n",
      "    print event.source_elapsed, event.description\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load Balancing Policies\n",
      "--------------------------\n",
      "\n",
      "The native driver will manage the connection pool for you, but by default it uses a `RoundRobinPolicy` to pick which server it talks to.  In your cluster, this means it'll talk to every machine in every datacenter.  This is ok if you only have 1 cluster but most of the time you're going to want to only talk to machines in the datacenter you're in.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cassandra.policies import DCAwareRoundRobinPolicy, TokenAwarePolicy\n",
      "\n",
      "# load local_dc string from environment or config in a real codebase\n",
      "policy = TokenAwarePolicy(DCAwareRoundRobinPolicy(local_dc='US_EAST')) \n",
      "\n",
      "token_aware_cluster = Cluster(['127.0.0.1'], load_balancing_policy=policy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}